import ollama



class LLMAgent:
    def __init__(self, model="llama3.1"):
        self.model = model
        # Implemente alguma forma de memória para armazenar o histórico de conversas.

    def generate(self, prompt):
        messages = [
            {'role': 'user',
                'content': prompt,
             }
        ]
        response = ollama.chat(model=self.model)
        return response

class Coder(LLMAgent):
    def __init__(self, model="llama3.1", problem_description=""):
        super().__init__(model)
        self.base_prompt = ("You a are a Python developer and data-scientist. Your job is to write code to solve data-science problems. "
                       "Be concise and mak sure to document your code.")
        self.problem_description = problem_description

    def generate_code(self, prompt):
        """
        Produz código baseado no prompt.

        :param prompt: descrição da tarefa de programação.
        :return: Código gerado como uma string.
        :return: Código gerado como uma string.
        """
        prompt = f"{self.base_prompt}.Considering the following problem:{self.problem_description}\n\n{prompt}"
        response = self.generate(prompt)
        return response['response']

class Revisor(LLMAgent):
    def __init__(self, model, problem_description=""):
        super().__init__(model)
        self.base_prompt = ("You are a Senior Python developer and data-scientist. "
                            "Your role is to review code generated by other developers and propose improvements like:"
                            "refactoring, optimization, and best practices.")
        self.problem_description = problem_description

    def _analise_estatica(self, code):
        """Implemente aqui análises estáticas do código"""
        return "No issues found."
    def review_code(self, code):
        """
        Revisa o código e retorna feedback.

        :param code: Código a ser revisado.
        :return: Feedback (string).
        """
        # Roda análise estática
        resultados = self._analise_estatica(code)
        # gera o feedback. Tente incorporar os resultados da análise estática no prompt.
        prompt = f"{self.base_prompt}.Considering the following problem:{self.problem_description}\n\nReview the code below  and provide feedback to the coder:\n{code}"
        feedback = self.generate(prompt)
        return feedback['response']



